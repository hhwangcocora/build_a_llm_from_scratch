{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "rDNmv2nO1z1R"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "4pNDm5i1Jfwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloaded from \"SMS Spam Collection\" UC Irvine\n",
        "spam_df = pd.read_csv('spam.csv', sep=',', header=None, names=['Label', 'Text', 'a', 'b', 'c'], encoding_errors='ignore')\n",
        "spam_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "a8RtD9s8_9nr",
        "outputId": "a99b6974-553b-4d75-d26b-b172b9d95725"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text    a    b    c\n",
              "0      ham  Go until jurong point, crazy.. Available only ...  NaN  NaN  NaN\n",
              "1      ham                      Ok lar... Joking wif u oni...  NaN  NaN  NaN\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...  NaN  NaN  NaN\n",
              "3      ham  U dun say so early hor... U c already then say...  NaN  NaN  NaN\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...  NaN  NaN  NaN\n",
              "...    ...                                                ...  ...  ...  ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...  NaN  NaN  NaN\n",
              "5568   ham               Will _ b going to esplanade fr home?  NaN  NaN  NaN\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...  NaN  NaN  NaN\n",
              "5570   ham  The guy did some bitching but I acted like i'd...  NaN  NaN  NaN\n",
              "5571   ham                         Rofl. Its true to its name  NaN  NaN  NaN\n",
              "\n",
              "[5572 rows x 5 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will _ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows Ã— 5 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spam_df['Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBl8ZOgmApe6",
        "outputId": "c2c80d72-b189-4c7e-cbbf-a937ea92e969"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_df['Label'] = spam_df['Label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# training: 70%\n",
        "# validation: 10%\n",
        "# testing: 20%\n",
        "def random_split(df, train_frac, validation_frac):\n",
        "  # Shuffle\n",
        "  df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "  train_end = int(len(df) * train_frac)\n",
        "  validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "  return df[:train_end], df[train_end:validation_end], df[validation_end:]\n",
        "\n",
        "train_df, validation_df, test_df = random_split(spam_df, 0.7, 0.1)\n"
      ],
      "metadata": {
        "id": "gItBQCBKDFYy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train dataset: len={len(train_df)}')\n",
        "print(f'Validation dataset: len={len(validation_df)}')\n",
        "print(f'Test dataset: len={len(test_df)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ylJ34TEcQ3",
        "outputId": "f8a727e6-cf18-4509-d83f-7605c3c637b5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: len=3900\n",
            "Validation dataset: len=557\n",
            "Test dataset: len=1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the data to csv files\n",
        "train_df.to_csv('train.csv', index=None)\n",
        "validation_df.to_csv('validation.csv', index=None)\n",
        "test_df.to_csv('test.csv', index=None)"
      ],
      "metadata": {
        "id": "XYgL9A9IFWCp"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Dataloader"
      ],
      "metadata": {
        "id": "xikkrAPX2BKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "  def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    self.encoded_text = [tokenizer.encode(text) for text in self.data['Text']]\n",
        "\n",
        "    if max_length is None:\n",
        "      self.max_length = self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "      self.encoded_text = [\n",
        "          text[:self.max_length] for text in self.encoded_text\n",
        "      ]\n",
        "    # Pad sequences to the longest sequence\n",
        "    self.encoded_text = [\n",
        "        text + [pad_token_id] * (self.max_length - len(text))\n",
        "        for text in self.encoded_text\n",
        "    ]\n",
        "\n",
        "  def _longest_encoded_length(self):\n",
        "    longest_length = 0\n",
        "    for text in self.encoded_text:\n",
        "      longest_length = max(longest_length, len(text))\n",
        "    return longest_length\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    encoded = self.encoded_text[index]\n",
        "    label = self.data.iloc[index]['Label']\n",
        "    return (\n",
        "        torch.tensor(encoded, dtype=torch.long),\n",
        "        torch.tensor(label, dtype=torch.long)\n",
        "    )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        ""
      ],
      "metadata": {
        "id": "fnxO7da62CdD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ],
      "metadata": {
        "id": "EKUEOKTA7Kwr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(csv_file=\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
        "print(train_dataset.max_length)\n",
        "print(train_dataset.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6KHafGE7EyU",
        "outputId": "b98d0024-da08-44c9-bcc4-3668a5ae5f53"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257\n",
            "3900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = SpamDataset(csv_file='validation.csv', max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "print(validation_dataset.max_length)\n",
        "print(validation_dataset.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU88G1O57imh",
        "outputId": "453848d4-77be-41fe-b8b1-cacd3579e4b4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257\n",
            "557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SpamDataset(csv_file='test.csv', max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "print(test_dataset.max_length)\n",
        "print(test_dataset.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx0iyBCT8CIq",
        "outputId": "2e4eaa23-afa0-4490-ef29-f759a85bbe9a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "257\n",
            "1115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True)\n",
        "validation_loader = DataLoader(\n",
        "    dataset=validation_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False)\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False)\n"
      ],
      "metadata": {
        "id": "YcnXJjP18OkY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train dataloader')\n",
        "for input, target in train_loader:\n",
        "  pass\n",
        "print(input)\n",
        "print(input.shape)\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7X7Lp4N8zLs",
        "outputId": "de7d7e53-c26c-4506-d4f5-46e5a47e5f2c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataloader\n",
            "tensor([[25374, 41649, 34509,  ..., 50256, 50256, 50256],\n",
            "        [10814,   986,  9576,  ..., 50256, 50256, 50256],\n",
            "        [39274,   337,  1546,  ..., 50256, 50256, 50256],\n",
            "        ...,\n",
            "        [ 8642,    23,    13,  ..., 50256, 50256, 50256],\n",
            "        [   44,  6996, 33826,  ..., 50256, 50256, 50256],\n",
            "        [ 2061,  1645,   284,  ..., 50256, 50256, 50256]])\n",
            "torch.Size([8, 257])\n",
            "tensor([0, 0, 1, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))\n",
        "print(len(validation_loader))\n",
        "print(len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXQ9n9WN9oLY",
        "outputId": "c52e1575-7839-44db-fc3f-40b85ee5c088"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "487\n",
            "70\n",
            "140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pre-trained GPT Model"
      ],
      "metadata": {
        "id": "hdW36l57-1U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO"
      ],
      "metadata": {
        "id": "cD-6RotcHcwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Update the model architecture"
      ],
      "metadata": {
        "id": "RPjvCHZBJQnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the output head\n",
        "# We could technically use a single output head, but that requires modifying the loss function.\n",
        "# We choose a more general approach where the number of output nodes matches the number of classes.\n",
        "\n",
        "# First, freeze the model\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# This out_head has requires_grad = True by default\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG['emb_dim'], out_features=num_classes)\n",
        "\n",
        "# Unfree the last transformer block and the last layer norm\n",
        "for param in model.trf_blocks[-1].parameters():\n",
        "  param.requires_grad = True\n",
        "for param in model.final_norm.parameters():\n",
        "  param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "UjwPHr_pChsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "inputs = tokenizer.encode(\"how are you?\")\n",
        "with torch.no_grad():\n",
        "  outputs = model(inputs)\n",
        "\n",
        "print(f\"Output: {outputs}\\ndimensions: {outputs.shape}\")"
      ],
      "metadata": {
        "id": "TRSFQEqJIWZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function"
      ],
      "metadata": {
        "id": "awXDMiTcJJiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r_4I5lN_JO04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}