{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import os\n",
        "import re\n"
      ],
      "metadata": {
        "id": "b64TJUQWgUoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimpleTokenzierV1"
      ],
      "metadata": {
        "id": "zLpMb5c2jI0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for item in os.listdir('.'): # '.' refers to the current directory\n",
        "#     print(item)\n",
        "\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "nVjdmc09dmcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_mlE3ClQbeA"
      },
      "outputs": [],
      "source": [
        "with open('the-verdict.txt', 'r', encoding='utf-8') as f:\n",
        "  raw_txt = f.read()\n",
        "\n",
        "print(len(raw_txt))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove whitespace or not?\n",
        "#   Removing whitespaces reduces memory and computing requirement\n",
        "#   White spaces can be useful for text sensitive to the structure, like python indention\n",
        "preprossed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_txt)\n",
        "preprossed = [t.strip() for t in preprossed if t.strip()]\n",
        "print(preprossed[:10])\n",
        "print(len(preprossed))"
      ],
      "metadata": {
        "id": "Vz6HQH1ZgQqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary: all the unique tokens in alphbetically order\n",
        "\n",
        "\n",
        "# For tokens not in the vocab\n",
        "UNKNOWN_TOKEN = \"<|unk|>\"\n",
        "\n",
        "# Added between text sources.\n",
        "# Allow the LLM to process and understand the data better.\n",
        "END_OF_TEXT_TOKEN = \"<|endoftext|>\"\n",
        "\n",
        "# Following special tokens are used by different types of tokenizers\n",
        "# [BOS]: beginning of sequence\n",
        "# [EOS]: end of sequence\n",
        "# [PAD]: padding\n",
        "\n",
        "sorted_unique_tokens = sorted(set(preprossed))\n",
        "sorted_unique_tokens.extend([END_OF_TEXT_TOKEN, UNKNOWN_TOKEN])\n",
        "print(len(sorted_unique_tokens))"
      ],
      "metadata": {
        "id": "9HV7FQ0hh1dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode token to token id\n",
        "vocab = {token:id for id,token in enumerate(sorted_unique_tokens)}\n",
        "\n",
        "# for i, item in enumerate(vocab.items()):\n",
        "#   print(i, item)\n",
        "#   if i > 20:\n",
        "#     break"
      ],
      "metadata": {
        "id": "Pnra95vEkSJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenzierV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.token_to_id = vocab\n",
        "    self.id_to_token = {id:token for token,id in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [t.strip() for t in preprocessed if t.strip()]\n",
        "    preprocessed = [t if t in self.token_to_id else UNKNOWN_TOKEN for t in preprocessed]\n",
        "    return [self.token_to_id[t] for t in preprocessed]\n",
        "\n",
        "  def decode(self, ids):\n",
        "    tokens = [self.id_to_token[id] for id in ids]\n",
        "    text = \" \".join(tokens)\n",
        "    return re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)"
      ],
      "metadata": {
        "id": "FKppEdWFlMXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_v1 = SimpleTokenzierV1(vocab)"
      ],
      "metadata": {
        "id": "-4orvWMmoGt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"how are you, jessica!\"\n",
        "text2 = \"do you like tea?\"\n",
        "test_ids = tokenizer_v1.encode(\" <|endoftext|> \".join((text1, text2)))\n",
        "print(test_ids)\n",
        "print(tokenizer_v1.decode(test_ids))"
      ],
      "metadata": {
        "id": "1gOPlTcDoLJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BPE Tokenizer"
      ],
      "metadata": {
        "id": "Xr6Lw-Pl6-Jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "\n",
        "# The immediate space preceding the word and the word itself are encoded as a single token\n",
        "\n",
        "END_OF_TEXT_TOKEN = \"<|endoftext|>\"\n",
        "\n",
        "tokenizer_bpe = tiktoken.get_encoding('gpt2') # download pre-trained vocabulary and merge rules\n",
        "\n",
        "# texts = [\"\", \"I'm\", \"I'm\"]\n",
        "# test_ids = tokenizer_bpe.encode(END_OF_TEXT_TOKEN.join(texts), allowed_special={END_OF_TEXT_TOKEN})\n",
        "# print(test_ids)\n",
        "# print(tokenizer_bpe.decode(test_ids))"
      ],
      "metadata": {
        "id": "PhY5LMQn6_mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and DataLoader\n"
      ],
      "metadata": {
        "id": "kd0HOIVmje3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class DatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      # One pair contains max_length training targets\n",
        "      self.input_ids.append(torch.tensor(token_ids[i:i+max_length]))\n",
        "      self.target_ids.append(torch.tensor(token_ids[i+1:i+1+max_length]))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# Dataload will load the dataset efficiently\n",
        "# batch_size: The data the model has to process before updating the parameters\n",
        "#             The number of tensor pairs each dataloader iteration return\n",
        "#             Smaller batch_size requires less memory but more noisy small updates.\n",
        "#             Larger batch_size will make less noisy updates but take more time.\n",
        "# max_length: The context length (the sliding window size)\n",
        "# drop_last:  To drop the last batch if it's shorter to prevent loss spike during training\n",
        "# stride: word overlapping will create overfitting, larger stride also help go through the text faster\n",
        "# num_workders: process the input in parallel\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=False, drop_last=True, num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = DatasetV1(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "  return dataloader\n"
      ],
      "metadata": {
        "id": "Tm5GF5NkjiRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader = create_dataloader_v1(raw_txt)\n",
        "# data_iter = iter(dataloader)\n",
        "# first_batch = next(data_iter)\n",
        "# print(first_batch)"
      ],
      "metadata": {
        "id": "jkgZ_aEBowAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token Embeddings and Position Embeddings"
      ],
      "metadata": {
        "id": "AfK4FMUDwrhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gensim.downloader as api\n",
        "\n",
        "# # 300 dimension\n",
        "# # huggingface.co/fse/word2vec-google-news-300\n",
        "# # Download the vector\n",
        "# word_vectors = api.load(\"word2vec-google-news-300\")\n"
      ],
      "metadata": {
        "id": "IPWxxyMJwt4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(word_vectors['computer'])\n",
        "# print(word_vectors.most_similar(positive=['king', 'woman'], negative=['man'], topn=10))\n",
        "# print(word_vectors.similarity(['woman', 'man']))\n",
        "# print(word_vectors.similarity(['tokyo', 'kyoto']))\n",
        "# print(word_vectors.similarity(['fish', 'bicycle']))\n",
        "# print(np.linalg.norm(word_vectors['women'] - word_vectors['man']))\n",
        "# print(np.linalg.norm(word_vectors['snow'] - word_vectors['pixel']))"
      ],
      "metadata": {
        "id": "oaf4eVY8x5Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create a embedding layer weight matrix\n",
        "vocab_size = 50000\n",
        "embedding_size = 128\n",
        "context_length = 256\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# A simple lookup table that stores embedding of a fixed dictionary and size.\n",
        "# Initialized to random numbers.\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "# Position embedding weight matrix\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, embedding_size)\n",
        "\n",
        "\n",
        "# print(embedding_layer.weight)\n",
        "# print(embedding_layer(torch.tensor([3])))\n",
        "\n",
        "# input_ids = torch.tensor([2, 3, 5, 1])\n",
        "# print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "id": "rYsKRYRE1F0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_txt, batch_size=4)\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "\n",
        "\n",
        "token_embeddings = embedding_layer(inputs) # batch_size x context_length x embedding_size\n",
        "# print(token_embeddings.shape)\n",
        "# print(input)\n",
        "# print(torch.arange(0, context_length))\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(0, context_length)) # context_length x embedding_size\n",
        "input_embeddings = token_embeddings + pos_embeddings # python broadcasting\n",
        "print(input_embeddings[0])"
      ],
      "metadata": {
        "id": "k8MjKWp02agy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention"
      ],
      "metadata": {
        "id": "dAbSYJ3uUraC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_length = 64\n",
        "\n",
        "class SelfAttentionV1:\n",
        "  def __init__(self, embedding_size, qkv_length):\n",
        "    self.Wq = torch.nn.Parameter(torch.rand(embedding_size, qkv_length), requires_grad=False)\n",
        "    self.Wk = torch.nn.Parameter(torch.rand(embedding_size, qkv_length), requires_grad=False)\n",
        "    self.Wv = torch.nn.Parameter(torch.rand(embedding_size, qkv_length), requires_grad=False)\n",
        "\n",
        "  def forward(input_embeddings):\n",
        "    Q = input_embeddings @ self.Wq\n",
        "    K = input_embeddings @ self.Wk\n",
        "    V = input_embeddings @ self.Wv\n",
        "\n",
        "    print(Q.shape, K.shape, V.shape)\n",
        "\n",
        "    attention_scores = Q @ K.transpose(-1, -2)\n",
        "    attention_weights = torch.softmax(attention_scores / qkv_length**0.5, dim = -1)\n",
        "    context_vectors = attention_weights @ V\n",
        "\n",
        "    print(context_vectors[0])\n",
        "    return context_vectors\n"
      ],
      "metadata": {
        "id": "6Huigq8NUrCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_length = 64\n",
        "\n",
        "class SelfAttentionV1:\n",
        "  def __init__(self, embedding_size, qkv_length, qkv_bias=False):\n",
        "    self.Wq = torch.nn.Linear(embedding_size, qkv_length, bias=qkv_bias)\n",
        "    self.Wk = torch.nn.Linear(embedding_size, qkv_length, bias=qkv_bias)\n",
        "    self.Wv = torch.nn.Linear(embedding_size, qkv_length, bias=qkv_bias)\n",
        "\n",
        "  def forward(input_embeddings):\n",
        "    Q = self.Wq(input_embeddings)\n",
        "    K = self.Wk(input_embeddings)\n",
        "    V = self.Wv(input_embeddings)\n",
        "\n",
        "    print(Q.shape, K.shape, V.shape)\n",
        "\n",
        "    attention_scores = Q @ K.transpose(-1, -2)\n",
        "    attention_weights = torch.softmax(attention_scores / qkv_length**0.5, dim = -1)\n",
        "    context_vectors = attention_weights @ V\n",
        "\n",
        "    print(context_vectors[0])\n",
        "    return context_vectors\n"
      ],
      "metadata": {
        "id": "zu8FaXUFvST0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}